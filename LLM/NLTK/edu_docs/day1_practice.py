"""
Day 1 ì‹¤ìŠµ: NLTK Book íƒí—˜
ì‹¤í–‰ ë°©ë²•: python day1_practice.py
"""

from nltk.book import *

print("=" * 70)
print("ğŸ® Day 1 ì‹¤ìŠµ: NLTK Book íƒí—˜ ì‹œì‘!")
print("=" * 70)

# ============================================================================
# Part 1: í…ìŠ¤íŠ¸ ëª©ë¡ í™•ì¸
# ============================================================================
print("\nğŸ“š Part 1: ì‚¬ìš© ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ í™•ì¸")
print("-" * 70)

print("text1:", text1)
print("text2:", text2)
print("text3:", text3)
print("text4:", text4)
print("text5:", text5)

# ============================================================================
# Part 2: Concordance - ë‹¨ì–´ì˜ ë¬¸ë§¥ ì°¾ê¸°
# ============================================================================
print("\nğŸ” Part 2: Concordance - 'whale' ë‹¨ì–´ì˜ ë¬¸ë§¥")
print("-" * 70)

text1.concordance("whale", lines=5)

# ============================================================================
# Part 3: Similar - ë¹„ìŠ·í•œ ë§¥ë½ì˜ ë‹¨ì–´
# ============================================================================
print("\nğŸ¯ Part 3: Similar - 'monstrous'ì™€ ë¹„ìŠ·í•œ ë‹¨ì–´ë“¤")
print("-" * 70)

text1.similar("monstrous")

# ============================================================================
# Part 4: Common Contexts - ê³µí†µ ë¬¸ë§¥
# ============================================================================
print("\nğŸ”— Part 4: Common Contexts - 'ship'ê³¼ 'boat'ì˜ ê³µí†µ ë¬¸ë§¥")
print("-" * 70)

text1.common_contexts(["ship", "boat"])

# ============================================================================
# Part 5: ê¸°ë³¸ í†µê³„
# ============================================================================
print("\nğŸ“Š Part 5: Text1 (Moby Dick) ê¸°ë³¸ í†µê³„")
print("-" * 70)

total_words = len(text1)
unique_words = len(set(text1))
lexical_diversity = unique_words / total_words

print(f"ì´ ë‹¨ì–´ ìˆ˜: {total_words:,}")
print(f"ê³ ìœ  ë‹¨ì–´ ìˆ˜: {unique_words:,}")
print(f"ì–´íœ˜ ë‹¤ì–‘ì„±: {lexical_diversity:.4f}")

whale_count = text1.count("whale")
whale_percentage = 100 * whale_count / total_words
print(f"\n'whale' ë¹ˆë„ìˆ˜: {whale_count}íšŒ")
print(f"'whale' ë¹„ìœ¨: {whale_percentage:.4f}%")

# ============================================================================
# Part 6: ë¯¸ì…˜ 1-1 - ë‹¨ì–´ íƒì •
# ============================================================================
print("\n" + "=" * 70)
print("ğŸ® ë¯¸ì…˜ 1-1: ë‹¨ì–´ íƒì • - 'captain' ì¡°ì‚¬í•˜ê¸°")
print("=" * 70)

print("\n1. 'captain'ì˜ ë¬¸ë§¥:")
text1.concordance("captain", lines=5)

print("\n2. 'captain'ê³¼ ë¹„ìŠ·í•œ ë‹¨ì–´ë“¤:")
text1.similar("captain")

print("\n3. 'captain' ë¹ˆë„ìˆ˜:")
captain_count = text1.count("captain")
print(f"   'captain' ë“±ì¥ íšŸìˆ˜: {captain_count}íšŒ")

# ============================================================================
# Part 7: ë¯¸ì…˜ 1-2 - í…ìŠ¤íŠ¸ ë¹„êµ ë¶„ì„
# ============================================================================
print("\n" + "=" * 70)
print("ğŸ® ë¯¸ì…˜ 1-2: í…ìŠ¤íŠ¸ ë¹„êµ - text1 vs text4")
print("=" * 70)

# text1: Moby Dick (ì†Œì„¤)
text1_total = len(text1)
text1_unique = len(set(text1))
text1_diversity = text1_unique / text1_total

# text4: Inaugural Addresses (ì—°ì„¤ë¬¸)
text4_total = len(text4)
text4_unique = len(set(text4))
text4_diversity = text4_unique / text4_total

print("\n[Text1 - Moby Dick (ì†Œì„¤)]")
print(f"  ì´ ë‹¨ì–´ ìˆ˜: {text1_total:,}")
print(f"  ê³ ìœ  ë‹¨ì–´ ìˆ˜: {text1_unique:,}")
print(f"  ì–´íœ˜ ë‹¤ì–‘ì„±: {text1_diversity:.4f}")

print("\n[Text4 - Inaugural Addresses (ì—°ì„¤ë¬¸)]")
print(f"  ì´ ë‹¨ì–´ ìˆ˜: {text4_total:,}")
print(f"  ê³ ìœ  ë‹¨ì–´ ìˆ˜: {text4_unique:,}")
print(f"  ì–´íœ˜ ë‹¤ì–‘ì„±: {text4_diversity:.4f}")

print("\n[ë¶„ì„ ê²°ê³¼]")
if text1_diversity > text4_diversity:
    print(f"  â†’ Text1(ì†Œì„¤)ì´ Text4(ì—°ì„¤ë¬¸)ë³´ë‹¤ {text1_diversity - text4_diversity:.4f} ë” ë‹¤ì–‘í•œ ì–´íœ˜ ì‚¬ìš©")
else:
    print(f"  â†’ Text4(ì—°ì„¤ë¬¸)ì´ Text1(ì†Œì„¤)ë³´ë‹¤ {text4_diversity - text1_diversity:.4f} ë” ë‹¤ì–‘í•œ ì–´íœ˜ ì‚¬ìš©")

# ============================================================================
# Part 8: ë¯¸ì…˜ 1-3 - íŒ¨í„´ ë°œê²¬
# ============================================================================
print("\n" + "=" * 70)
print("ğŸ® ë¯¸ì…˜ 1-3: íŒ¨í„´ ë°œê²¬ - text2 (Sense and Sensibility)")
print("=" * 70)

print("\n1. 'love'ì™€ 'hate'ì˜ ê³µí†µ ë¬¸ë§¥:")
text2.common_contexts(["love", "hate"])

print("\n2. 'Mr'ì™€ 'Mrs'ì˜ ê³µí†µ ë¬¸ë§¥:")
text2.common_contexts(["Mr", "Mrs"])

love_count = text2.count("love")
hate_count = text2.count("hate")
mr_count = text2.count("Mr")
mrs_count = text2.count("Mrs")

print("\n[ë¹ˆë„ ë¶„ì„]")
print(f"  'love': {love_count}íšŒ")
print(f"  'hate': {hate_count}íšŒ")
print(f"  'Mr': {mr_count}íšŒ")
print(f"  'Mrs': {mrs_count}íšŒ")

# ============================================================================
# Part 9: ì¶”ê°€ ë„ì „ ê³¼ì œ - 9ê°œ í…ìŠ¤íŠ¸ ë¹„êµ
# ============================================================================
print("\n" + "=" * 70)
print("ğŸ† ì¶”ê°€ ë„ì „ ê³¼ì œ: 9ê°œ í…ìŠ¤íŠ¸ ì–´íœ˜ ë‹¤ì–‘ì„± ë¹„êµ")
print("=" * 70)

texts_dict = {
    "Text1: Moby Dick": text1,
    "Text2: Sense & Sensibility": text2,
    "Text3: Genesis": text3,
    "Text4: Inaugural": text4,
    "Text5: Chat": text5,
    "Text6: Monty Python": text6,
    "Text7: Wall Street Journal": text7,
    "Text8: Personals": text8,
    "Text9: Chesterton": text9
}

diversity_results = []

print("\nì–´íœ˜ ë‹¤ì–‘ì„± ìˆœìœ„:")
print("-" * 70)

for name, text in texts_dict.items():
    diversity = len(set(text)) / len(text)
    diversity_results.append((name, diversity, len(text), len(set(text))))

# ë‹¤ì–‘ì„± ìˆœìœ¼ë¡œ ì •ë ¬
diversity_results.sort(key=lambda x: x[1], reverse=True)

for rank, (name, diversity, total, unique) in enumerate(diversity_results, 1):
    print(f"{rank}. {name}")
    print(f"   ì–´íœ˜ ë‹¤ì–‘ì„±: {diversity:.4f} (ì „ì²´: {total:,}, ê³ ìœ : {unique:,})")

print("\n[ë¶„ì„]")
print(f"ê°€ì¥ ë‹¤ì–‘: {diversity_results[0][0]} ({diversity_results[0][1]:.4f})")
print(f"ê°€ì¥ ë‹¨ìˆœ: {diversity_results[-1][0]} ({diversity_results[-1][1]:.4f})")

# ============================================================================
# ì™„ë£Œ!
# ============================================================================
print("\n" + "=" * 70)
print("âœ… Day 1 ì‹¤ìŠµ ì™„ë£Œ!")
print("=" * 70)
print("\níšë“ ê²½í—˜ì¹˜:")
print("  - ì¼ì¼ ê³¼ì œ: +10 XP")
print("  - ë¯¸ì…˜ 1-1: +50 XP")
print("  - ë¯¸ì…˜ 1-2: +50 XP")
print("  - ë¯¸ì…˜ 1-3: +50 XP")
print("  - ì¶”ê°€ ë„ì „: +25 XP")
print("  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
print("  ì´ íšë“: +185 XP")
print("\nì§„í–‰ë„: 185 / 200 XP (Level 2ê¹Œì§€ 15 XP ë‚¨ìŒ!)")
print("\në‹¤ìŒ: Day 2 - Tokenization (í† í°í™”) ê¸°ì´ˆ")
print("=" * 70)
