# Day 1: NLTK ê¸°ì´ˆ íƒí—˜ - ì™„ì „ ì‹¤ìŠµ ê°€ì´ë“œ

## ğŸ¯ í•™ìŠµ ëª©í‘œ
1. nltk.bookì˜ 9ê°œ í…ìŠ¤íŠ¸ ì´í•´í•˜ê¸°
2. Concordance, Similar, Common Contexts í•¨ìˆ˜ ì‚¬ìš©ë²• ìµíˆê¸°
3. í…ìŠ¤íŠ¸ ê¸°ë³¸ í†µê³„ ê³„ì‚°í•˜ê¸°

---

## ğŸ“š Step 1: í…ìŠ¤íŠ¸ ëª©ë¡ í™•ì¸

```python
from nltk.book import *

# ì‚¬ìš© ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ë“¤
# text1: Moby Dick by Herman Melville 1851
# text2: Sense and Sensibility by Jane Austen 1811
# text3: The Book of Genesis
# text4: Inaugural Address Corpus
# text5: Chat Corpus
# text6: Monty Python and the Holy Grail
# text7: Wall Street Journal
# text8: Personals Corpus
# text9: The Man Who Was Thursday by G. K. Chesterton 1908

# í™•ì¸í•´ë³´ê¸°
print(text1)
print(text2)
```

**ì¶œë ¥ ì˜ˆì‹œ:**
```
<Text: Moby Dick by Herman Melville 1851>
<Text: Sense and Sensibility by Jane Austen 1811>
```

---

## ğŸ” Step 2: Concordance - ë‹¨ì–´ê°€ ì‚¬ìš©ëœ ë¬¸ë§¥ ì°¾ê¸°

**ì„¤ëª…:** íŠ¹ì • ë‹¨ì–´ê°€ ì–´ë–¤ ë¬¸ë§¥ì—ì„œ ì‚¬ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸

```python
# 'whale'ì´ë¼ëŠ” ë‹¨ì–´ê°€ text1ì—ì„œ ì–´ë–»ê²Œ ì‚¬ìš©ë˜ì—ˆëŠ”ì§€
text1.concordance("whale")

# ì¶œë ¥ ì˜ˆì‹œ:
# Displaying 25 of 906 matches:
# ong the former , one was of a most monstrous size . ... This came towards us , 
# ON OF THE PSALMS . "Touching that monstrous bulk of the whale or ork we have r
# ll over with a heathenish array of monstrous clubs and spears . Some were thick
# d as you gazed , and wondered what monstrous cannibal and savage could ever hav
```

**ì‹¤ìŠµ ê³¼ì œ:**
```python
# 1. text1ì—ì„œ 'sea'ë¼ëŠ” ë‹¨ì–´ì˜ ë¬¸ë§¥ ì°¾ê¸°
text1.concordance("sea")

# 2. text2ì—ì„œ 'love'ë¼ëŠ” ë‹¨ì–´ì˜ ë¬¸ë§¥ ì°¾ê¸° (ì œì¸ ì˜¤ìŠ¤í‹´ ì†Œì„¤)
text2.concordance("love")

# 3. text4ì—ì„œ 'freedom'ì´ë¼ëŠ” ë‹¨ì–´ì˜ ë¬¸ë§¥ ì°¾ê¸° (ëŒ€í†µë ¹ ì—°ì„¤ë¬¸)
text4.concordance("freedom")

# 4. ê²°ê³¼ë¥¼ ì œí•œí•˜ê³  ì‹¶ë‹¤ë©´ (ì²˜ìŒ 5ê°œë§Œ)
text1.concordance("whale", lines=5)
```

---

## ğŸ¯ Step 3: Similar - ë¹„ìŠ·í•œ ë§¥ë½ì˜ ë‹¨ì–´ ì°¾ê¸°

**ì„¤ëª…:** íŠ¹ì • ë‹¨ì–´ì™€ ë¹„ìŠ·í•œ ë¬¸ë§¥ì—ì„œ ì‚¬ìš©ëœ ë‹¤ë¥¸ ë‹¨ì–´ë“¤ ì°¾ê¸°

```python
# 'monstrous'ì™€ ë¹„ìŠ·í•œ ë§¥ë½ìœ¼ë¡œ ì‚¬ìš©ëœ ë‹¨ì–´ë“¤
text1.similar("monstrous")

# ì¶œë ¥ ì˜ˆì‹œ:
# true contemptible christian abundant few part mean careful puzzled
# mystifying passing curious loving wise doleful gamesome singular
# delightfully perilous fearful threatening
```

**ì‹¤ìŠµ ê³¼ì œ:**
```python
# 1. text1ì—ì„œ 'ship'ê³¼ ë¹„ìŠ·í•œ ë§¥ë½ì˜ ë‹¨ì–´
text1.similar("ship")

# 2. text2ì—ì„œ 'happy'ì™€ ë¹„ìŠ·í•œ ë§¥ë½ì˜ ë‹¨ì–´
text2.similar("happy")

# 3. text3ì—ì„œ 'God'ì™€ ë¹„ìŠ·í•œ ë§¥ë½ì˜ ë‹¨ì–´ (ì„±ê²½)
text3.similar("God")
```

**ì™œ ì´ê²Œ ì¤‘ìš”í•œê°€ìš”?**
- ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ë¬¸ë§¥ì„ í†µí•´ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ë™ì˜ì–´ë‚˜ ìœ ì‚¬í•œ ê°œë…ì„ ë°œê²¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ì‘ê°€ì˜ ì–´íœ˜ ì‚¬ìš© íŒ¨í„´ì„ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

---

## ğŸ”— Step 4: Common Contexts - ê³µí†µ ë¬¸ë§¥ ì°¾ê¸°

**ì„¤ëª…:** ë‘ ë‹¨ì–´ê°€ ê³µí†µì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ë¬¸ë§¥ ì°¾ê¸°

```python
# 'ship'ê³¼ 'boat'ê°€ ê³µí†µìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ” ë¬¸ë§¥
text1.common_contexts(["ship", "boat"])

# ì¶œë ¥ ì˜ˆì‹œ:
# the_is a_. the_was
```

**í•´ì„:** "the ship is", "the boat is", "a ship.", "a boat." ë“±ì˜ íŒ¨í„´ì—ì„œ ê³µí†µì ìœ¼ë¡œ ì‚¬ìš©ë¨

**ì‹¤ìŠµ ê³¼ì œ:**
```python
# 1. text1ì—ì„œ 'sea'ì™€ 'ocean'ì˜ ê³µí†µ ë¬¸ë§¥
text1.common_contexts(["sea", "ocean"])

# 2. text2ì—ì„œ 'man'ê³¼ 'woman'ì˜ ê³µí†µ ë¬¸ë§¥
text2.common_contexts(["man", "woman"])

# 3. text4ì—ì„œ 'people'ê³¼ 'citizens'ì˜ ê³µí†µ ë¬¸ë§¥
text4.common_contexts(["people", "citizens"])
```

---

## ğŸ“Š Step 5: í…ìŠ¤íŠ¸ ê¸°ë³¸ í†µê³„

```python
# ì´ ë‹¨ì–´ ìˆ˜ (í† í° ê°œìˆ˜)
print(len(text1))
# ì¶œë ¥: 260819

# ê³ ìœ  ë‹¨ì–´ ìˆ˜ (ì¤‘ë³µ ì œê±°)
print(len(set(text1)))
# ì¶œë ¥: 19317

# ì–´íœ˜ ë‹¤ì–‘ì„± (Lexical Diversity)
# = ê³ ìœ  ë‹¨ì–´ ìˆ˜ / ì „ì²´ ë‹¨ì–´ ìˆ˜
lexical_diversity = len(set(text1)) / len(text1)
print(f"ì–´íœ˜ ë‹¤ì–‘ì„±: {lexical_diversity:.4f}")
# ì¶œë ¥: ì–´íœ˜ ë‹¤ì–‘ì„±: 0.0741

# íŠ¹ì • ë‹¨ì–´ì˜ ë¹ˆë„ìˆ˜
print(text1.count("whale"))
# ì¶œë ¥: 906

# íŠ¹ì • ë‹¨ì–´ê°€ ì „ì²´ì—ì„œ ì°¨ì§€í•˜ëŠ” ë¹„ìœ¨ (%)
word_percentage = 100 * text1.count("whale") / len(text1)
print(f"'whale'ì˜ ë¹„ìœ¨: {word_percentage:.4f}%")
# ì¶œë ¥: 'whale'ì˜ ë¹„ìœ¨: 0.3473%
```

**ì‹¤ìŠµ ê³¼ì œ: í…ìŠ¤íŠ¸ ë¹„êµ ë¶„ì„**
```python
# ì—¬ëŸ¬ í…ìŠ¤íŠ¸ì˜ ì–´íœ˜ ë‹¤ì–‘ì„± ë¹„êµ
texts = [text1, text2, text3, text4, text5]
names = ["Moby Dick", "Sense & Sensibility", "Genesis", "Inaugural", "Chat"]

for text, name in zip(texts, names):
    diversity = len(set(text)) / len(text)
    print(f"{name}: {diversity:.4f}")

# ì˜ˆìƒ ê²°ê³¼:
# Moby Dick: 0.0741
# Sense & Sensibility: 0.0485
# Genesis: 0.0620
# Inaugural: 0.0617
# Chat: 0.1332  <- ì±„íŒ…ì€ ì–´íœ˜ê°€ ë‹¤ì–‘í•¨!
```

---

## ğŸ“ˆ Step 6: Dispersion Plot (ì‹œê°í™”)

**ì„¤ëª…:** í…ìŠ¤íŠ¸ ì „ì²´ì—ì„œ íŠ¹ì • ë‹¨ì–´ë“¤ì´ ì–´ë””ì— ë“±ì¥í•˜ëŠ”ì§€ ì‹œê°í™”

```python
# matplotlibê°€ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤
# pip install matplotlib

from nltk.book import text4  # ëŒ€í†µë ¹ ì—°ì„¤ë¬¸

# ì£¼ìš” ì •ì¹˜ ìš©ì–´ë“¤ì˜ ë¶„í¬ í™•ì¸
text4.dispersion_plot(["citizens", "democracy", "freedom", "duties", "America"])
```

**ê·¸ë˜í”„ ì—†ì´ ìœ„ì¹˜ í™•ì¸í•˜ê¸°:**
```python
# íŠ¹ì • ë‹¨ì–´ê°€ ë‚˜íƒ€ë‚˜ëŠ” ìœ„ì¹˜ ì°¾ê¸°
def find_word_positions(text, word, max_positions=10):
    positions = [i for i, w in enumerate(text) if w.lower() == word.lower()]
    print(f"'{word}' ë“±ì¥ íšŸìˆ˜: {len(positions)}íšŒ")
    print(f"ì²˜ìŒ {max_positions}ê°œ ìœ„ì¹˜: {positions[:max_positions]}")
    return positions

# ì‹¤ìŠµ
find_word_positions(text1, "whale", 10)
find_word_positions(text4, "freedom", 10)
```

---

## ğŸ® Day 1 ë¯¸ì…˜: í…ìŠ¤íŠ¸ íƒí—˜ê°€

**ë¯¸ì…˜ 1-1: ë‹¨ì–´ íƒì •**
```python
# TODO: text1ì—ì„œ 'captain'ì´ë¼ëŠ” ë‹¨ì–´ë¥¼ ì¡°ì‚¬í•˜ì„¸ìš”
# 1. concordanceë¡œ ë¬¸ë§¥ í™•ì¸
# 2. similarë¡œ ë¹„ìŠ·í•œ ë‹¨ì–´ ì°¾ê¸°
# 3. countë¡œ ë¹ˆë„ìˆ˜ í™•ì¸

# ì—¬ê¸°ì— ì½”ë“œ ì‘ì„±:



```

**ë¯¸ì…˜ 1-2: í…ìŠ¤íŠ¸ ë¹„êµ ë¶„ì„ê°€**
```python
# TODO: text1(ì†Œì„¤)ê³¼ text4(ì—°ì„¤ë¬¸)ì„ ë¹„êµí•˜ì„¸ìš”
# 1. ê°ê°ì˜ ì´ ë‹¨ì–´ ìˆ˜
# 2. ê°ê°ì˜ ê³ ìœ  ë‹¨ì–´ ìˆ˜  
# 3. ê°ê°ì˜ ì–´íœ˜ ë‹¤ì–‘ì„±
# 4. ì–´ëŠ í…ìŠ¤íŠ¸ê°€ ë” ë‹¤ì–‘í•œ ì–´íœ˜ë¥¼ ì‚¬ìš©í•˜ëŠ”ê°€?

# ì—¬ê¸°ì— ì½”ë“œ ì‘ì„±:



```

**ë¯¸ì…˜ 1-3: íŒ¨í„´ ë°œê²¬ì**
```python
# TODO: text2(ì œì¸ ì˜¤ìŠ¤í‹´ ì†Œì„¤)ì—ì„œ
# 1. 'love'ì™€ 'hate'ì˜ ê³µí†µ ë¬¸ë§¥ ì°¾ê¸°
# 2. 'Mr'ì™€ 'Mrs'ì˜ ê³µí†µ ë¬¸ë§¥ ì°¾ê¸°
# 3. ë‘ íŒ¨í„´ì„ ë¹„êµí•˜ê³  ë¶„ì„í•˜ê¸°

# ì—¬ê¸°ì— ì½”ë“œ ì‘ì„±:



```

---

## âœ… Day 1 ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] `from nltk.book import *` ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰
- [ ] text1ë¶€í„° text9ê¹Œì§€ ì–´ë–¤ í…ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
- [ ] concordance() í•¨ìˆ˜ë¡œ ìµœì†Œ 3ê°œ ë‹¨ì–´ì˜ ë¬¸ë§¥ í™•ì¸
- [ ] similar() í•¨ìˆ˜ë¡œ ìµœì†Œ 3ê°œ ë‹¨ì–´ì˜ ìœ ì‚¬ì–´ ì°¾ê¸°
- [ ] common_contexts() í•¨ìˆ˜ë¡œ ìµœì†Œ 2ìŒì˜ ê³µí†µ ë¬¸ë§¥ í™•ì¸
- [ ] len(), set(), count() í•¨ìˆ˜ë¡œ í†µê³„ ê³„ì‚°
- [ ] ì–´íœ˜ ë‹¤ì–‘ì„±(lexical diversity) ê°œë… ì´í•´
- [ ] ë¯¸ì…˜ 1-1, 1-2, 1-3 ì™„ë£Œ

---

## ğŸ† Day 1 ì„±ê³¼

**íšë“ ê²½í—˜ì¹˜:** +10 XP (ì¼ì¼ ê³¼ì œ) + 50 XP (ë¯¸ì…˜ ì™„ë£Œ) = **60 XP**

**ë°°ìš´ ê°œë…:**
- NLTKì˜ Text ê°ì²´
- Concordance (ë¬¸ë§¥ ë¶„ì„)
- Similarity (ìœ ì‚¬ì–´ ì°¾ê¸°)
- Common Contexts (ê³µí†µ ë¬¸ë§¥)
- ì–´íœ˜ ë‹¤ì–‘ì„± (Lexical Diversity)
- ë¹ˆë„ ë¶„ì„

**ë‹¤ìŒ ë‹¨ê³„:** Day 2 - í† í°í™”(Tokenization) ê¸°ì´ˆ

---

## ğŸ’¡ ì¶”ê°€ ë„ì „ ê³¼ì œ (+25 XP)

```python
# ë„ì „ ê³¼ì œ: 9ê°œ í…ìŠ¤íŠ¸ ì¤‘ ê°€ì¥ ì–´íœ˜ê°€ ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ ì°¾ê¸°

texts_dict = {
    "Moby Dick": text1,
    "Sense & Sensibility": text2,
    "Genesis": text3,
    "Inaugural": text4,
    "Chat": text5,
    "Monty Python": text6,
    "WSJ": text7,
    "Personals": text8,
    "Chesterton": text9
}

# TODO: ê° í…ìŠ¤íŠ¸ì˜ ì–´íœ˜ ë‹¤ì–‘ì„±ì„ ê³„ì‚°í•˜ê³ 
# ê°€ì¥ ë†’ì€ ê²ƒê³¼ ê°€ì¥ ë‚®ì€ ê²ƒì„ ì°¾ìœ¼ì„¸ìš”
# ì™œ ê·¸ëŸ° ì°¨ì´ê°€ ë‚˜ëŠ”ì§€ ë¶„ì„í•´ë³´ì„¸ìš”

# ì—¬ê¸°ì— ì½”ë“œ ì‘ì„±:



```

---


